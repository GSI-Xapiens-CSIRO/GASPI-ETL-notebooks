{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas==2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Identifiable Information (PII) Detection using LSTM\n",
    "\n",
    "This notebook demonstrates how to detect and mask sensitive personal data \n",
    "such as national ID numbers, phone numbers, and vehicle plate numbers using \n",
    "an LSTM-based deep learning model. The model is trained to classify whether \n",
    "a given text contains PII. Additionally, regex-based filtering is applied \n",
    "to enhance detection accuracy.\n",
    "\n",
    "## Setup: Imports, Configurations, Regex, and Model\n",
    "\n",
    "We start by importing the necessary libraries for data processing (`pandas`), deep learning (`torch`), and text preprocessing (`tensorflow.keras.preprocessing.text`).  \n",
    "The model is configured with predefined hyperparameters, and regex patterns are used for detecting PII such as national IDs, phone numbers, and vehicle plate numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 16:38:32.536136: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model configuration, including preprocessing parameters and model hyperparameters\n",
    "MODEL_CONFIG = {\n",
    "    \"preprocessing\": {\n",
    "        \"padding\": {\"max_length\": 20, \"padding_mode\": \"pre\"},\n",
    "        \"label_encoding\": {\"pii\": 1, \"non-pii\": 0},\n",
    "        \"tokenizer\": {\"flname\": \"pii_tokenizer.json\"},\n",
    "    },\n",
    "    \"models\": {\n",
    "        \"name\": \"model_hyperparams_epoch50_layer5_lr01.pth\",\n",
    "        \"hyperparams\": {\n",
    "            \"vocab_size\": 28229,\n",
    "            \"output_dim\": 1,\n",
    "            \"embedding_dim\": 128,\n",
    "            \"hidden_dim\": 128,\n",
    "            \"num_layers\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define regex patterns to detect sensitive data such as NIK (Indonesian ID number),\n",
    "# mobile phone numbers, home phone numbers, and vehicle plate numbers.\n",
    "NIK_REGEX = re.compile(r\"^(1[1-9]|21|[37][1-6]|5[1-3]|6[1-5]|[89][12])\\d{2}\\d{2}([04][1-9]|[1256][0-9]|[37][01])(0[1-9]|1[0-2])\\d{2}\\d{4}$\")\n",
    "MOBILE_PHONE_REGEX = re.compile(r\"^(\\+62|62)?[\\s-]?0?8[1-9]{1}\\d{1}[\\s-]?\\d{4}[\\s-]?\\d{2,5}$\")\n",
    "PLATE_NUMBER_REGEX = re.compile(r\"^[A-Z]{1,2}\\s{0,1}\\d{0,4}\\s{0,1}[A-Z]{0,3}$\")\n",
    "HOME_PHONE_REGEX = re.compile(r\"^(\\+62|62)?[\\s-]?0?([2-7]|9)\\d(\\d)?[\\s-]?[2-9](\\d){6,7}\")\n",
    "\n",
    "# Define an LSTM-based model for PII detection\n",
    "class LSTIMPii(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTIMPii, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        logits = self.fc(lstm_out[:, -1, :])\n",
    "        return logits\n",
    "\n",
    "# Define a class for handling PII prediction\n",
    "class PredictingPII:\n",
    "    def __init__(self, input_folder, output_folder):\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.hyperparams = MODEL_CONFIG[\"models\"][\"hyperparams\"]\n",
    "        self.model = self._instantiate_model()\n",
    "        self.tokenizer = self._load_tokenizer()\n",
    "\n",
    "    # Instantiate and load the model with pretrained weights\n",
    "    def _instantiate_model(self):\n",
    "        model = LSTIMPii(\n",
    "            vocab_size=self.hyperparams[\"vocab_size\"],\n",
    "            embedding_dim=self.hyperparams[\"embedding_dim\"],\n",
    "            hidden_dim=self.hyperparams[\"hidden_dim\"],\n",
    "            output_dim=self.hyperparams[\"output_dim\"],\n",
    "            num_layers=self.hyperparams[\"num_layers\"],\n",
    "        )\n",
    "        model.load_state_dict(torch.load(MODEL_CONFIG[\"models\"][\"name\"], map_location=self.device))\n",
    "        return model.to(self.device)\n",
    "\n",
    "    # Load the tokenizer from a JSON file\n",
    "    def _load_tokenizer(self):\n",
    "        with open(MODEL_CONFIG[\"preprocessing\"][\"tokenizer\"][\"flname\"], \"r\") as file:\n",
    "            return tokenizer_from_json(file.read())\n",
    "\n",
    "    # Preprocess text data before feeding it to the model\n",
    "    def _preprocess(self, data):\n",
    "        sequences = self.tokenizer.texts_to_sequences(data.astype(str))\n",
    "        padded = pad_sequences(sequences, maxlen=MODEL_CONFIG[\"preprocessing\"][\"padding\"][\"max_length\"], padding=\"pre\")\n",
    "        return torch.tensor(padded, dtype=torch.long).to(self.device)\n",
    "    \n",
    "    # Predict and mask PII data in a CSV file\n",
    "    def predict(self, file_name):\n",
    "        input_path = os.path.join(self.input_folder, file_name)\n",
    "        output_path = os.path.join(self.output_folder, f\"predicted_{file_name}\")\n",
    "\n",
    "        df = pd.read_csv(input_path)\n",
    "        self.model.eval()\n",
    "\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].astype(str).apply(\n",
    "                lambda x: \"*****\" if NIK_REGEX.match(x) or MOBILE_PHONE_REGEX.match(x) or PLATE_NUMBER_REGEX.match(x) or HOME_PHONE_REGEX.match(x) else x\n",
    "            )\n",
    "            input_data = self._preprocess(df[column])\n",
    "            with torch.no_grad():\n",
    "                predictions = (self.model(input_data).squeeze(1) > 0.5).long()\n",
    "            df[column] = df[column].apply(lambda x: \"*****\" if predictions[0].item() == 1 else x)\n",
    "        \n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Processed {file_name} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PII Detection on CSV Files\n",
    "This script will:\n",
    "\n",
    "- Instantiate the prediction class\n",
    "- Loop through all CSV files in the input/ folder\n",
    "- Run the predict function on each file\n",
    "- Make sure to put your files on the input folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dummy_medical_data.csv -> output/predicted_dummy_medical_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the PII detection process on all CSV files in the input folder\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = PredictingPII(input_folder=\"input\", output_folder=\"output\")\n",
    "    for file in os.listdir(\"input\"):\n",
    "        if file.endswith(\".csv\"):\n",
    "            predictor.predict(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
