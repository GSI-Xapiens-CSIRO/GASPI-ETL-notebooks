{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca5aaa3",
   "metadata": {},
   "source": [
    "# Download and analyse dataportal log events\n",
    "\n",
    "## Downloading log events\n",
    "\n",
    "We are going to analyse the log events of user `admin@example.com` (an admin/manager user).\n",
    "\n",
    "To perform this task, you must have aws console access, because the keys are needed to access aws console via the cli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37961c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"admin@example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "690eb3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_dataportal_logs.sh\n"
     ]
    }
   ],
   "source": [
    "%%file download_dataportal_logs.sh\n",
    "\n",
    "#!/bin/bash\n",
    "LOG_GROUP_NAME=\"/aws/lambda/sbeacon-backend-dataPortal\"\n",
    "REGION=\"ap-southeast-2\"\n",
    "\n",
    "# Get all log stream names\n",
    "log_streams=$(aws logs describe-log-streams \\\n",
    "  --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "  --query 'logStreams[*].logStreamName' \\\n",
    "  --output text \\\n",
    "  --region $REGION)\n",
    "\n",
    "for stream in $log_streams; do\n",
    "  echo \"Downloading logs for stream: $stream\"\n",
    "  safe_stream_name=$(echo \"$stream\" | sed 's/\\//_/g')\n",
    "  output_file=\"dataportal_${safe_stream_name}.json\"\n",
    "  > \"$output_file\"  # Clear/create file\n",
    "\n",
    "  next_token=\"\"\n",
    "  first_request=true\n",
    "\n",
    "  while : ; do\n",
    "    if [ \"$first_request\" = true ]; then\n",
    "      response=$(aws logs get-log-events \\\n",
    "        --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "        --log-stream-name \"$stream\" \\\n",
    "        --start-from-head \\\n",
    "        --region $REGION \\\n",
    "        --output json)\n",
    "      first_request=false\n",
    "    else\n",
    "      response=$(aws logs get-log-events \\\n",
    "        --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "        --log-stream-name \"$stream\" \\\n",
    "        --next-token \"$next_token\" \\\n",
    "        --region $REGION \\\n",
    "        --output json)\n",
    "    fi\n",
    "\n",
    "    # Save events (append only the \"events\" array)\n",
    "    echo \"$response\" | jq '.events' >> \"$output_file\"\n",
    "\n",
    "    # Get the nextForwardToken for the next page\n",
    "    new_token=$(echo \"$response\" | jq -r '.nextForwardToken')\n",
    "\n",
    "    # If the next token is the same as the previous, we're done\n",
    "    if [ \"$next_token\" == \"$new_token\" ]; then\n",
    "      break\n",
    "    fi\n",
    "    next_token=$new_token\n",
    "  done\n",
    "\n",
    "  echo \"Finished downloading $stream\"\n",
    "done\n",
    "\n",
    "echo \"All log streams downloaded.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32215d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run follwing command with keys in the terminal\n",
    "# bash download_dataportal_logs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db65815",
   "metadata": {},
   "source": [
    "## Loading the events for dataportal log group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540ef555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "def iterate_log_entries():\n",
    "    entries = []\n",
    "    for file in glob(\"dataportal_*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = f.read()\n",
    "            data = data.replace(\"[]\\n\", \"\")\n",
    "            entries +=  json.loads(data)\n",
    "    \n",
    "    log_entry = []\n",
    "    for entry in entries:\n",
    "        log_entry.append(entry)\n",
    "        if entry[\"message\"].startswith(\"REPORT\"):\n",
    "            yield log_entry\n",
    "            log_entry = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952ed58",
   "metadata": {},
   "source": [
    "Admins can use the sub of this user to track their login and logout activities in cloudtrail. You can get sub of this user using the following command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws cognito-idp list-users --user-pool-id <user-pool-id> --filter \"email = \\\"<email>\\\"\"\n",
    "\n",
    "# for example\n",
    "# aws cognito-idp list-users --user-pool-id ap-southeast-2_3ZrrcagIG --filter \"email = \\\"admin@example.com\\\"\" --region ap-southeast-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0641aa",
   "metadata": {},
   "source": [
    "Output would look like follows\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Users\": [\n",
    "    {\n",
    "      \"Username\": \"admin@example.com\",\n",
    "      \"Attributes\": [\n",
    "        {\n",
    "          \"Name\": \"email\",\n",
    "          \"Value\": \"admin@example.com\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"email_verified\",\n",
    "          \"Value\": \"true\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"family_name\",\n",
    "          \"Value\": \"Admin\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"given_name\",\n",
    "          \"Value\": \"Admin\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"custom:terraform\",\n",
    "          \"Value\": \"true\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"custom:identity_id\",\n",
    "          \"Value\": \"ap-southeast-2:099e873d-80b5-cb64-b9b4-0f64c663bd46\"\n",
    "        },\n",
    "        {\n",
    "          \"Name\": \"sub\",\n",
    "          \"Value\": \"f98e24c8-2011-70ae-9d93-084eb3f4b282\"\n",
    "        }\n",
    "      ],\n",
    "      \"UserCreateDate\": \"2024-11-20T15:58:30.157000+10:30\",\n",
    "      \"UserLastModifiedDate\": \"2025-03-13T15:09:11.817000+10:30\",\n",
    "      \"Enabled\": true,\n",
    "      \"UserStatus\": \"CONFIRMED\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ae754",
   "metadata": {},
   "source": [
    "## Dataportal notebook events for the user admin@example.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a851b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User admin@example.com listed details of notebook: new-test, at 1747798600351\n",
      "User admin@example.com started notebook: new-test, at 1747798604247\n",
      "User admin@example.com listed details of notebook: new-test, at 1747798604446\n",
      "User admin@example.com listed details of notebook: new-test, at 1747798606108\n",
      "User admin@example.com created a notebook at 1747798620851\n",
      "\tNotebook properties:\n",
      "\t{\n",
      "\t    \"instanceName\": \"My-test-notebook\",\n",
      "\t    \"instanceType\": \"ml.t3.medium\",\n",
      "\t    \"volumeSize\": 5,\n",
      "\t    \"identityId\": \"ap-southeast-2:099e873d-80b5-cb64-b9b4-0f64c663bd46\"\n",
      "\t}\n",
      "User admin@example.com listed details of notebook: new-test, at 1747798621244\n",
      "User admin@example.com listed notebooks at 1747798600351\n",
      "User admin@example.com listed details of notebook: testNotebook, at 1747798621244\n",
      "User admin@example.com listed details of notebook: testNotebook, at 1747798600341\n",
      "User admin@example.com listed notebooks at 1747798621256\n",
      "User admin@example.com listed details of notebook: My-test-notebook, at 1747798621700\n",
      "User admin@example.com listed details of notebook: My-test-notebook, at 1747801107794\n",
      "User admin@example.com stopped notebook: My-test-notebook, at 1747801110222\n",
      "User admin@example.com listed details of notebook: My-test-notebook, at 1747801110371\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "import re\n",
    "from urllib.parse import unquote\n",
    "\n",
    "re_notebook_start = re.compile(r\"^/dportal/notebooks/.*?/start$\")\n",
    "re_notebook_stop = re.compile(r\"^/dportal/notebooks/.*?/stop$\")\n",
    "re_notebook = re.compile(r\"^/dportal/notebooks/[a-zA-Z0-9-]+$\")\n",
    "\n",
    "for log_entry in iterate_log_entries():\n",
    "    log_event = list(filter(lambda x: x[\"message\"].startswith(\"Event Received\"), log_entry))[0]\n",
    "    event = log_event[\"message\"]\n",
    "    event = event.replace(\"Event Received: \", \"\")\n",
    "    event = json.loads(event)\n",
    "    \n",
    "\n",
    "    if not event[\"requestContext\"][\"authorizer\"][\"claims\"][\"email\"] == user:\n",
    "        continue\n",
    "\n",
    "    if event[\"httpMethod\"] == \"POST\" and event[\"path\"] == \"/dportal/notebooks\":\n",
    "        print(f\"User {user} created a notebook at {log_event['timestamp']}\")\n",
    "        print(\"\\tNotebook properties:\")\n",
    "        print(indent(json.dumps(json.loads(event[\"body\"]), indent=4), \"\\t\"))\n",
    "\n",
    "    elif re_notebook_start.match(event[\"path\"]):\n",
    "        print(f\"User {user} started notebook: {event['path'].split('/')[-2]}, at {log_event[\"timestamp\"]}\")\n",
    "    \n",
    "    elif re_notebook_stop.match(event[\"path\"]):\n",
    "        print(f\"User {user} stopped notebook: {event['path'].split('/')[-2]}, at {log_event[\"timestamp\"]}\")\n",
    "\n",
    "    elif re_notebook.match(event[\"path\"]):\n",
    "        print(f\"User {user} listed details of notebook: {event['path'].split('/')[-1]}, at {log_event[\"timestamp\"]}\")\n",
    "\n",
    "    elif \"/dportal/notebooks\" == event[\"path\"]:\n",
    "        print(f\"User {user} listed notebooks at {log_event['timestamp']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb2a6f",
   "metadata": {},
   "source": [
    "## Dataportal manager tasks performed by user admin@example.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9134e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User admin@example.com deleted notebook: delete, at 1747804819990\n",
      "User admin@example.com listed projects at 1747804373824\n",
      "User admin@example.com listed projects at 1747804378229\n",
      "User admin@example.com updated details of project: My test project, at 1747804386554\n",
      "\tProject properties:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz.tbi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com listed projects at 1747798660520\n",
      "User admin@example.com listed projects at 1747798676185\n",
      "User admin@example.com listed projects at 1747798689686\n",
      "User admin@example.com ingested data into project: Example Query Project, at 1747798819096\n",
      "\tIngest properties:\n",
      "\t{\n",
      "\t    \"s3Payload\": \"s3://gasi-dataportal-20241120071209060300000001/projects/Example Query Project/project-files/chr1-metadata.json\",\n",
      "\t    \"vcfLocations\": [\n",
      "\t        \"s3://gasi-dataportal-20241120071209060300000001/projects/Example Query Project/project-files/chr1.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com listed projects at 1747798842926\n",
      "User admin@example.com indexed data into sBeacon at 1747798851518\n",
      "User admin@example.com listed details of notebook: My-test-notebook-f98e24c8-2011-70ae-9d93-084eb3f4b282, at 1747801121885\n",
      "User admin@example.com listed folders at 1747801126136\n",
      "User admin@example.com listed folders at 1747801128387\n",
      "User admin@example.com listed projects at 1747804806988\n",
      "User admin@example.com listed notebooks at 1747804807645\n",
      "User admin@example.com created a project at 1747798551150\n",
      "\tProject properties:\n",
      "\t{\n",
      "\t    \"name\": \"My test project\",\n",
      "\t    \"description\": \"This is a test project\"\n",
      "\t}\n",
      "User admin@example.com listed projects at 1747798553212\n",
      "User admin@example.com listed projects at 1747798556336\n",
      "User admin@example.com updated details of project: My test project, at 1747798578696\n",
      "\tProject properties:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project\",\n",
      "\t    \"files\": [\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com listed projects at 1747798594573\n",
      "User admin@example.com listed notebooks at 1747801114726\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "import re\n",
    "from urllib.parse import unquote\n",
    "\n",
    "re_projects = re.compile(r\"^/dportal/admin/projects$\")\n",
    "re_project = re.compile(r\"^/dportal/admin/projects/[a-zA-Z%0-9]+$\")\n",
    "re_projects_ingest = re.compile(r\"^/dportal/admin/projects/[a-zA-Z%0-9]+/ingest/[a-zA-Z%0-9-]+$\")\n",
    "re_notebook_delete = re.compile(r\"^/dportal/admin/notebooks/[a-zA-Z-0-9]+/delete$\")\n",
    "re_notebook = re.compile(r\"^/dportal/admin/notebooks/[a-zA-Z-0-9]+$\")\n",
    "\n",
    "for log_entry in iterate_log_entries():\n",
    "    log_event = list(filter(lambda x: x[\"message\"].startswith(\"Event Received\"), log_entry))[0]\n",
    "    event = log_event[\"message\"]\n",
    "    event = event.replace(\"Event Received: \", \"\")\n",
    "    event = json.loads(event)\n",
    "    \n",
    "\n",
    "\n",
    "    if not event[\"requestContext\"][\"authorizer\"][\"claims\"][\"email\"] == user or \"/dportal/admin\" not in event[\"path\"]:\n",
    "        continue\n",
    "\n",
    "    #\n",
    "    # Projects\n",
    "    #\n",
    "    \n",
    "    if event[\"httpMethod\"] == \"POST\" and re_projects.match(event[\"path\"]):\n",
    "        print(f\"User {user} created a project at {log_event['timestamp']}\")\n",
    "        print(\"\\tProject properties:\")\n",
    "        print(indent(json.dumps(json.loads(event[\"body\"]), indent=4), \"\\t\"))\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"GET\" and re_projects.match(event[\"path\"]):\n",
    "        print(f\"User {user} listed projects at {log_event['timestamp']}\")\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"GET\" and re_project.match(event[\"path\"]):\n",
    "        print(f\"User {user} listed details of project: {event['path'].split('/')[-1]}, at {log_event['timestamp']}\")\n",
    "\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"PUT\" and re_project.match(event[\"path\"]):\n",
    "        print(f\"User {user} updated details of project: {unquote(event['path'].split('/')[-1])}, at {log_event['timestamp']}\")\n",
    "        print(\"\\tProject properties:\")\n",
    "        print(indent(json.dumps(json.loads(event[\"body\"]), indent=4), \"\\t\"))\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"POST\" and re_projects_ingest.match(event[\"path\"]):\n",
    "        print(f\"User {user} ingested data into project: {unquote(event['path'].split('/')[-3])}, at {log_event['timestamp']}\")\n",
    "        print(\"\\tIngest properties:\")\n",
    "        print(indent(json.dumps(json.loads(event[\"body\"]), indent=4), \"\\t\"))\n",
    "\n",
    "    # \n",
    "    # sBeacon \n",
    "    #\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"POST\" and event[\"path\"] == \"/dportal/admin/sbeacon/index\":\n",
    "        print(f\"User {user} indexed data into sBeacon at {log_event['timestamp']}\")\n",
    "\n",
    "    # \n",
    "    # notebooks\n",
    "    # \n",
    "\n",
    "    elif event[\"httpMethod\"] == \"GET\" and event[\"path\"] == \"/dportal/admin/notebooks\":\n",
    "        print(f\"User {user} listed notebooks at {log_event['timestamp']}\")\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"GET\" and re_notebook.match(event[\"path\"]):\n",
    "        print(f\"User {user} listed details of notebook: {unquote(event['path'].split('/')[-1])}, at {log_event['timestamp']}\")\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"POST\" and re_notebook_delete.match(event[\"path\"]):\n",
    "        print(f\"User {user} deleted notebook: {unquote(event['path'].split('/')[-1])}, at {log_event['timestamp']}\")\n",
    "\n",
    "    elif event[\"httpMethod\"] == \"GET\" and event[\"path\"] == \"/dportal/admin/folders\":\n",
    "        print(f\"User {user} listed folders at {log_event['timestamp']}\")\n",
    "\n",
    "    else:\n",
    "        print(\"MISSED EVENT\", event[\"httpMethod\"], event[\"path\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c98450",
   "metadata": {},
   "source": [
    "## Dataportal file delete events for the user admin@example.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71799250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User admin@example.com updated project: projects, at 1747836813726\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747836990255\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747837059915\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747837988140\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747804386554\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz.tbi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747871525716\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"test-de-identity-progress\",\n",
      "\t    \"files\": [\n",
      "\t        \"chr22_SNV_INDEL_SV_phased.vcf.gz.csi\",\n",
      "\t        \"pharmcat.example.vcf.gz\",\n",
      "\t        \"10000850402.vcf.gz.csi\",\n",
      "\t        \"10000850402.vcf.gz\",\n",
      "\t        \"10000830402.vcf.gz\",\n",
      "\t        \"pharmcat.example.vcf.gz.csi\",\n",
      "\t        \"10000830402.vcf.gz.csi\",\n",
      "\t        \"chr22_SNV_INDEL_SV_phased.vcf.gz\"\n",
      "\t    ]\n",
      "\t}\n",
      "\tAction: Deleting minimal.vcf.gz,minimal.vcf.gz.csi from project \"test-de-identity-progress\" by user admin@example.com\n",
      "User admin@example.com updated project: projects, at 1747871594747\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747837137382\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747837319526\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747833558394\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747814325833\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747814448015\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\",\n",
      "\t        \"minimal.vcf.gz.csi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747798578696\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project\",\n",
      "\t    \"files\": [\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\"\n",
      "\t    ]\n",
      "\t}\n",
      "User admin@example.com updated project: projects, at 1747837582809\n",
      "\tUpdate payload:\n",
      "\t{\n",
      "\t    \"description\": \"This is a test project - updated\",\n",
      "\t    \"files\": [\n",
      "\t        \"wrong.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.csi\",\n",
      "\t        \"minimal.vcf.gz\",\n",
      "\t        \"minimal.vcf.gz.tbi\"\n",
      "\t    ]\n",
      "\t}\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "import re\n",
    "from urllib.parse import unquote\n",
    "\n",
    "re_admin_projects = re.compile(r\"^/dportal/admin/projects/[a-zA-Z0-9%-]+$\")\n",
    "\n",
    "\n",
    "for complete_log_entry in iterate_log_entries():\n",
    "    log_event = list(filter(lambda x: x[\"message\"].startswith(\"Event Received\"), complete_log_entry))[0]\n",
    "    event = log_event[\"message\"]\n",
    "    event = event.replace(\"Event Received: \", \"\")\n",
    "    event = json.loads(event)\n",
    "    \n",
    "\n",
    "    if not event[\"requestContext\"][\"authorizer\"][\"claims\"][\"email\"] == user:\n",
    "        continue\n",
    "\n",
    "    if event[\"httpMethod\"] == \"PUT\" and re_admin_projects.match(event[\"path\"]):\n",
    "        print(f\"User {user} updated project: {event['path'].split('/')[-2]}, at {log_event['timestamp']}\")\n",
    "        delete_log_event = list(filter(lambda x: x[\"message\"].startswith(\"Deleting\"), complete_log_entry))\n",
    "\n",
    "        print(\"\\tUpdate payload:\")\n",
    "        print(indent(json.dumps(json.loads(event[\"body\"]), indent=4), \"\\t\"))\n",
    "        for delete_event in delete_log_event:\n",
    "            print(f\"\\tAction: {delete_event['message'].strip()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16b35f",
   "metadata": {},
   "source": [
    "## Dataportal file add events for the user admin@example.com\n",
    "\n",
    "This tracks all file uploads regardless if they are invalid files or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f025b8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing download_deidentify_logs.sh\n"
     ]
    }
   ],
   "source": [
    "%%file download_deidentify_logs.sh\n",
    "\n",
    "#!/bin/bash\n",
    "LOG_GROUP_NAME=\"/aws/lambda/sbeacon-backend-deidentifyFiles\"\n",
    "REGION=\"ap-southeast-2\"\n",
    "\n",
    "# Get all log stream names\n",
    "log_streams=$(aws logs describe-log-streams \\\n",
    "  --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "  --query 'logStreams[*].logStreamName' \\\n",
    "  --output text \\\n",
    "  --region $REGION)\n",
    "\n",
    "for stream in $log_streams; do\n",
    "  echo \"Downloading logs for stream: $stream\"\n",
    "  safe_stream_name=$(echo \"$stream\" | sed 's/\\//_/g')\n",
    "  output_file=\"deidentify_${safe_stream_name}.json\"\n",
    "  > \"$output_file\"  # Clear/create file\n",
    "\n",
    "  next_token=\"\"\n",
    "  first_request=true\n",
    "\n",
    "  while : ; do\n",
    "    if [ \"$first_request\" = true ]; then\n",
    "      response=$(aws logs get-log-events \\\n",
    "        --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "        --log-stream-name \"$stream\" \\\n",
    "        --start-from-head \\\n",
    "        --region $REGION \\\n",
    "        --output json)\n",
    "      first_request=false\n",
    "    else\n",
    "      response=$(aws logs get-log-events \\\n",
    "        --log-group-name \"$LOG_GROUP_NAME\" \\\n",
    "        --log-stream-name \"$stream\" \\\n",
    "        --next-token \"$next_token\" \\\n",
    "        --region $REGION \\\n",
    "        --output json)\n",
    "    fi\n",
    "\n",
    "    # Save events (append only the \"events\" array)\n",
    "    echo \"$response\" | jq '.events' >> \"$output_file\"\n",
    "\n",
    "    # Get the nextForwardToken for the next page\n",
    "    new_token=$(echo \"$response\" | jq -r '.nextForwardToken')\n",
    "\n",
    "    # If the next token is the same as the previous, we're done\n",
    "    if [ \"$next_token\" == \"$new_token\" ]; then\n",
    "      break\n",
    "    fi\n",
    "    next_token=$new_token\n",
    "  done\n",
    "\n",
    "  echo \"Finished downloading $stream\"\n",
    "done\n",
    "\n",
    "echo \"All log streams downloaded.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe2939",
   "metadata": {},
   "source": [
    "## Loading the events for deidentify log group\n",
    "\n",
    "This is the log group that records file uploads immediately after uploads are completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5de580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "def iterate_log_entries():\n",
    "    entries = []\n",
    "    for file in glob(\"deidentify_*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = f.read()\n",
    "            data = data.replace(\"[]\\n\", \"\")\n",
    "            entries +=  json.loads(data)\n",
    "    \n",
    "    log_entry = []\n",
    "    for entry in entries:\n",
    "        log_entry.append(entry)\n",
    "        if entry[\"message\"].startswith(\"REPORT\"):\n",
    "            yield log_entry\n",
    "            log_entry = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ec22290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"admin@example.com\" created file: \"wrong.vcf.gz\" in project: \"My test project\" at 1747871597084\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "import re\n",
    "from urllib.parse import unquote\n",
    "\n",
    "for complete_log_entry in iterate_log_entries():\n",
    "    log_event = list(filter(lambda x: x[\"message\"].startswith(\"Backend Event Received:\"), complete_log_entry))[0]\n",
    "\n",
    "    if file_event := list(filter(lambda x: x[\"message\"].startswith(\"File owner\"), complete_log_entry)):\n",
    "        pattern = r'File owner for \"(.*?)\" of project \"(.*?)\" is \"(.*?)\"'\n",
    "        match = re.match(pattern, file_event[0][\"message\"])\n",
    "        if match:\n",
    "            file_name, project, user_sub = match.groups()\n",
    "            print(f'User: \"{user_sub}\" created file: \"{file_name}\" in project: \"{project}\" at {log_event[\"timestamp\"]}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
